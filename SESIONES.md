# SESIONES.md ‚Äî mis_finanzas_1.0

**√öltima actualizaci√≥n**: 2026-02-24 ‚Äî Sesi√≥n 43 COMPLETADA

---

## üî¥ Decisiones Arquitect√≥nicas (PERMANENTES ‚Äî NO repetir)

Estas decisiones ya se tomaron. No volver a preguntar ni proponer alternativas.

| # | Decisi√≥n | Por qu√© | Sesi√≥n |
|---|----------|---------|--------|
| 1 | SQLite, no PostgreSQL | Proyecto local sin concurrencia | S1-2 |
| 2 | Taxonom√≠a v2.2: Devoluciones como Cat2 | Cat2 dentro de cada GASTO, no Cat1 independiente | S3 |
| 3 | Clasificador 5 capas sin ML | Basado en reglas prioritarias + merchants + transfers + tokens | S1-2 |
| 4 | Reglas en classifier/, nunca BD | Correcciones en engine.py, merchants.py, tokens.py ‚Äî reprocesar con reclassify_all.py | S1 |
| 5 | Idioma espa√±ol | Todo c√≥digo, comentarios, comunicaci√≥n en espa√±ol | S1 |
| 6 | Bit√°cora √∫nica SESIONES.md | Fuente de verdad centralizada, actualizar tras cada bloque | S9 |
| 7 | Inversi√≥n/Intereses ‚Üí INGRESO/Intereses | Intereses cobrados son ingresos, no inversiones | S12 |
| 8 | Pr√©stamos ‚Üí Finanzas/Pr√©stamos | Pr√©stamos como Cat2 de Finanzas, no Cat1 independiente | S12 |

---

## üü° Estado Operativo

### M√©tricas Principales

| M√©trica | Valor | C√≥mo verificar |
|---------|-------|----------------|
| Total transacciones | 14,634 (‚Üì1,027 de S42) | `sqlite3 finsense.db "SELECT COUNT(*) FROM transacciones;"` |
| Trade Republic | 0 (‚Üì1,027 borradas en S43) | `sqlite3 finsense.db "SELECT COUNT(*) FROM transacciones WHERE banco='Trade Republic';"` |
| Cat2=Otros | 543 | `sqlite3 finsense.db "SELECT COUNT(*) FROM transacciones WHERE cat2='Otros';"` |
| SIN_CLASIFICAR | 99 (detectadas en S43) | `sqlite3 finsense.db "SELECT COUNT(*) FROM transacciones WHERE cat1='SIN_CLASIFICAR';"` |
| Cobertura clasificaci√≥n | 99.3% (99 sin clasificar = 0.7%) | 99% vs 96.5% en S42 |
| Periodo cubierto | 2004-05-03 ‚Üí 2026-02-13 | `sqlite3 finsense.db "SELECT MIN(fecha), MAX(fecha) FROM transacciones;"` |
| Bancos soportados | 6 (sin TR temporalmente) | Openbank, MyInvestor, Mediolanum, Revolut, B100, Abanca |
| Maestro CSV vigente | v29 (vigente S23-24, actualizar post-S40) | `validate/Validacion_Categorias_Finsense_MASTER_v29.csv` |
| Combinaciones Cat1\|Cat2 v√°lidas | 188 | `classifier/valid_combos.py` |

### Pendientes Activos

**ALTA**:
- [x] REGLA #35: 6 txs "COMPRAS Y OPERACIONES CON TARJETA 4B" positivas ‚Üí Compras/Devoluciones. ‚úÖ COMPLETADA
- [x] REGLAS #36-#45: ~85 txs con keywords en merchant ‚Üí categor√≠as correctas. ‚úÖ COMPLETADAS
- [x] S43: Limpiar duplicados TR + alertas sin clasificar. ‚úÖ COMPLETADA
- [ ] Enmascarar tarjetas en OTROS parsers (Abanca, B100, etc.) ‚Äî fase 2 (baja prioridad, solo Openbank afectado)

**MEDIA**:
- [ ] 99 txs sin clasificar: 3 restaurantes (TR), ~23 Bizums TR, ~73 movimientos MyInvestor/TR. Evaluar estrategia de cobertura.
- [ ] Auditor√≠a Fase 2 duplicados: Openbank (200 pares), Abanca (112 pares), B100 (51 pares) ‚Äî BAJA prioridad

**BAJA**:
- [ ] Mediolanum: CSV cuando est√© listo ‚Äî bot procesar√° autom√°ticamente
- [ ] Comando `/sin_clasificar` ‚Äî producci√≥n ready, solo listado de √∫ltimas 20

---

## üü¢ √öltimas Sesiones (m√°x 5 ‚Äî las anteriores van a ARCHIVO)

### S43 ‚Äî 2026-02-24 ‚Äî DUPLICADOS + ALERTAS SIN CLASIFICAR ‚úÖ COMPLETADO
- **Hecho**: ‚úÖ (1) **Diagn√≥stico cr√≠tico**: 99 txs sin clasificar en BD (3 recientes TR: Biergarten, El Horno de Ricote, La Frontera). Causa: m√≥dulo `recurrent_merchants.py` solo act√∫a sobre `cat2='Otros'`, nunca sobre `SIN_CLASIFICAR`. (2) **Duplicados reales encontrados**: Openbank SIMYO (rowid 44393 vs 47647 ‚Äî tarjeta completa vs enmascarada) + AECC de TR (rowid 47910 vs 48862 ‚Äî texto truncado vs completo). Causa: hash usa descripci√≥n literal; variaciones entre fuentes = hashes distintos = deduplicaci√≥n falla. (3) **Plan de limpieza TR**: Borrar 1,027 txs de Trade Republic (duplicados con PDFs solapados). Moveir ficheros de `input/procesados/` a `input/tr_backup_temp/`. Usuario subir√° PDF limpio por Telegram. (4) **Fix preventivo en openbank.py**: Nueva funci√≥n `_normalize_description_for_hash()` que enmascarar n√∫meros de tarjeta (5489... ‚Üí XXXX...2036) ANTES de generar hash. Ambas descripciones generan ahora el MISMO hash (test: ‚úÖ hash1==hash2). Impacto: futuras importaciones Openbank con tarjeta completa/enmascarada ser√°n deduplicadas correctamente. (5) **Alertas bot**: Post-importaci√≥n, muestra contador de txs sin clasificar + comando `/sin_clasificar` para ver listado completo (√∫ltimas 20 con paginaci√≥n). Detecci√≥n via rowid: compara MAX(rowid) antes/despu√©s de procesamiento. (6) **Limpiezas**: Backup BD creado (`finsense.db.backup_antes_borrado_TR_20260224`). Borradas 1,027 txs TR ‚Üí total 15,661‚Üí14,634 txs. Reseteado `ultimo_rowid_push_diario = 47647` (nueva MAX(rowid)). (7) **Bot relanzado**: PID 2760608, nuevo comando registrado, logs limpios, sintaxis verificada.
- **M√©trica**: 1,027 txs borradas. 99 sin clasificar identificadas. Fix preventivo: enmascarado de tarjetas en openbank.py. 2 ficheros modificados. Commit 00e31d2.
- **Decisi√≥n**: Dedup fallida por variaciones de descripci√≥n resuelto. Future: enmascarar tarjetas en TODOS los parsers (Openbank es fase 1). Alertas sin clasificar: Opci√≥n C (contador + `/sin_clasificar`).
- **Pr√≥ximo**: Usuario env√≠a PDF TR limpio por Telegram. Bot procesar√° con nuevo fix de openbank.py ‚Üí sin duplicados con tarjeta enmascarada. Comando `/sin_clasificar` disponible para auditar.

### S42 ‚Äî 2026-02-24 ‚Äî PUSH DIARIO: SOLO ENVIAR SI HAY CAMBIOS ‚úÖ COMPLETADO
- **Hecho**: ‚úÖ (1) **Problema identificado**: `push_diario()` enviaba mensaje TODOS los d√≠as a las 12:00, sin verificar si hubo nuevas importaciones de transacciones. Desperdiciaba credenciales de LLM. (2) **Soluci√≥n implementada**: Detecci√≥n de cambios usando `MAX(rowid)` de `transacciones` vs. valor guardado en nueva tabla `bot_estado`. (3) **Implementaci√≥n detallada**: (a) Crear tabla `bot_estado(clave TEXT PK, valor TEXT)` con `CREATE TABLE IF NOT EXISTS` al primer llamado. (b) Leer `MAX(rowid)` actual de `transacciones` (~48,888). (c) Leer `ultimo_rowid_push_diario` de `bot_estado` (inicialmente `-1`). (d) **L√≥gica**: Si `max_rowid == ultimo_rowid` ‚Üí omitir push (log: "‚è≠Ô∏è Push diario omitido: no hay nuevas txs"). Si `max_rowid != ultimo_rowid` ‚Üí generar, enviar, y guardar nuevo rowid. (4) **Testing manual**: Simuladas 3 ejecuciones: primera (enviar ‚úì), segunda sin cambios (omitir ‚úì), tercera con nueva tx insertada (enviar ‚úì). (5) **BD verificaci√≥n**: Tabla `bot_estado` creada, registro `ultimo_rowid_push_diario = 48888` guardado. (6) **Bot reiniciado**: PID 2631620, scheduler corriendo, logs limpios, sin errores de sintaxis.
- **M√©trica**: ~35 l√≠neas de c√≥digo nuevo en `push_diario()`. Tabla `bot_estado` implementada. Bot PID 2631620.
- **Decisi√≥n**: Push diario ahora inteligente ‚Äî solo env√≠a cuando hay cambios en BD (nuevas importaciones). Reduce uso innecesario de API/LLM.
- **Pr√≥ximo**: Pr√≥ximo `push_diario()` se ejecutar√° a las 12:00 ma√±ana. Si sin cambios desde hoy (48,888 rowid), se omitir√° autom√°ticamente. Si usuario env√≠a CSV/PDF por Telegram antes, incrementar√° rowid y se enviar√° el push.

### S41 ‚Äî 2026-02-24 ‚Äî INTEGRACI√ìN CLAUDE API (FALLBACK LLM) ‚úÖ COMPLETADO
- **Hecho**: ‚úÖ (1) **Instalaci√≥n paquete `anthropic`**: v0.83.0 instalado en venv (9 nuevas dependencias incluidas). (2) **Configuraci√≥n `.env`**: Clave ANTHROPIC_API_KEY actualizada (2 intentos: sk-ant-api03-xG4... ‚Üí error 401; sk-ant-api03-RFvIVy... ‚Üí error 404 sin acceso a modelos). (3) **Cadena fallback LLM completada**: (a) Intenta Qwen (API local) ‚Üí (b) Si falla, intenta Claude API ‚Üí (c) Si ambos fallan, devuelve an√°lisis en formato crudo. (4) **Diagn√≥stico**: Primera clave: error autenticaci√≥n. Segunda clave: aut√©ntica pero sin permisos acceso a modelos (posiblemente clave test/desarrollo deshabilitada). (5) **Soluci√≥n**: Bot funciona perfectamente con Qwen como LLM principal. Fallback Claude en c√≥digo listo para cuando haya clave v√°lida con acceso a modelos.
- **M√©trica**: +anthropic (9 deps), fallback chain implementada, bot PID 2568178 corriendo. Logs limpios.
- **Decisi√≥n**: Mantener c√≥digo tal como est√°. Cuando tengas clave v√°lida con acceso a modelos Claude, bot usar√° Claude autom√°ticamente sin cambios.
- **Pr√≥ximo**: Bot operativo con Qwen. Si necesitas Claude, contactar Anthropic para habilitar acceso a modelos en la clave.

### S40 ‚Äî 2026-02-24 ‚Äî FIX DOCUMENTO HANDLER + HISTORIAL.MD PERMANENTE ‚úÖ COMPLETADO
- **Hecho**: ‚úÖ (1) **Fix cr√≠tico en `bot_telegram.py`** (l√≠nea 513-518): Verificaci√≥n `if file_path.exists():` antes de `shutil.move()`. Problema: handler mov√≠a archivos ya movidos por pipeline‚Üíerror "no such file". Soluci√≥n: comprobar antes de mover; si no existe, loguear que fue movido por pipeline. (2) **Compactaci√≥n SESIONES.md**: 143‚Üí82 l√≠neas (-43%). Conservadas S36-S40 √≠ntegras, S31-S35 en siguiente compactaci√≥n. (3) **Creaci√≥n HISTORIAL.md**: Archivo permanente (653 l√≠neas) con S1-S40 completos, organizado en 3 fases. Nunca se compacta ni se borra. (4) **Actualizaci√≥n AGENTS.md**: Protocolo compactaci√≥n ‚Üí mover sesiones COMPLETAS a HISTORIAL.md (no resumir). (5) **M√©tricas actualizadas**: 15,661 txs, 2026-02-23, Cat2=Otros 543 (3.5%).
- **M√©trica**: SESIONES.md -43%, HISTORIAL.md +653 l√≠neas (24 sesiones archivadas), AGENTS.md actualizado, bot reiniciado (PID 2537328), 3 jobs OK. Coste tokens: 0 (HISTORIAL.md no se lee en cada sesi√≥n).
- **Commit**: 31367a1 "S40: crear HISTORIAL.md permanente + actualizar protocolo compactaci√≥n"
- **Pr√≥ximo**: (1) Mediolanum CSV por Telegram; (2) Nuevos PDFs TR; (3) Auditor√≠a Fase 2 duplicados (baja prioridad).

### S39 ‚Äî 2026-02-24 ‚Äî IMPORTACI√ìN DE FICHEROS V√çA TELEGRAM ‚úÖ COMPLETADO
- **Hecho**: ‚úÖ SISTEMA DE IMPORTACI√ìN DE DOCUMENTOS IMPLEMENTADO. (1) **Desactivado sync de pytr**: eliminadas l√≠neas 301-332 en push_diario() ‚Äî el CSV de TR est√° descartado, solo PDFs v√≠a Telegram. (2) **Nuevo handler de documentos**: funci√≥n `async def documento_handler()` (~130 l√≠neas) que: (a) Verifica autorizaci√≥n (solo TELEGRAM_USER_ID), (b) Descarga PDF/CSV a input/, (c) Ejecuta process_transactions.py en background, (d) Parsea resultado para extraer nuevas_txs, (e) Notifica al usuario, (f) Archiva en input/procesados/. (3) **Registro del handler**: a√±adido `MessageHandler(filters.Document.ALL, documento_handler)` en main(). (4) **Actualizaci√≥n /ayuda**: secci√≥n "Importar documentos" con instrucciones. (5) **Pruebas**: bot reiniciado (PID 2531313), scheduler corriendo, logs OK. (6) **840 txs nuevas importadas** desde PDF TR completo.
- **M√©trica**: +130 l√≠neas handler. Bot funcional. BD: 15,661 txs.
- **Decisi√≥n**: Importaci√≥n de documentos es √∫nico flujo entrada para PDFs/CSVs.

### S38 ‚Äî 2026-02-24 ‚Äî LIMPIEZA DE DUPLICADOS TR ‚úÖ COMPLETADO
- **Hecho**: ‚úÖ FASE 1 LIMPIEZA DUPLICADOS. (1) **Investigaci√≥n**: 679 pares duplicados l√≥gicos identificados. (2) **Ejecuci√≥n**: Eliminadas 924 txs del CSV de S23. Carpeta `input/descartados/` creada con CSV movido. PDFs archivados en `input/archivo_tr/`. (3) **Resultado**: BD 15,745‚Üí14,821 txs (-924). TR: 187 txs solo de PDFs oficiales (cero contaminaci√≥n).
- **M√©trica**: 924 txs eliminadas. BD limpia.
- **Decisi√≥n**: CSV descartado definitivamente. TR usa solo PDFs.

### S35 ‚Äî 2026-02-23 ‚Äî BLOQUE 2: AUTOMATIZACI√ìN TRADE REPUBLIC ‚úÖ
- **Hecho**: ‚úÖ `sync_trade_republic.py` (395 l√≠neas) + integraci√≥n bot_telegram.py. Instalado pytr v0.4.6. Sync autom√°tico diario a las 12:00 con deduplicaci√≥n correcta.
- **M√©trica**: Bot corriendo (PID 2247104). 3 jobs programados. Tests: dry-run ‚úÖ, real ‚úÖ.

### S34 ‚Äî 2026-02-23 ‚Äî BLOQUE 3: SISTEMA 3-LEVEL DE MENSAJES ‚úÖ
- **Hecho**: ‚úÖ SISTEMA 3-LEVEL IMPLEMENTADO. (1) **Daily (12:00)**: 8 √°ngulos aleatorios + 5 tonos rotativos. (2) **Monthly (d√≠a 1, 08:00)**: 3 √°ngulos rotativos. (3) **Annual (1 ene, 08:00)**: Revisi√≥n anual fija con proyecci√≥n FIRE. Bot reiniciado (PID 2218166). Scheduler: 3 jobs registrados.
- **M√©trica**: advisor.py: +560 l√≠neas.

---

## üìñ Historial Completo

Ver `HISTORIAL.md` para todas las sesiones pasadas (S1‚ÄìS40). El archivo nunca se compacta ni se borra.
Nuevo protocolo: cada 5 sesiones, las antiguas se mueven a HISTORIAL.md completas (sin resumir).
