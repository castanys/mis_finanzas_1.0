#!/usr/bin/env python3
"""
Test manual del pipeline completo.
"""
import os
from pipeline import TransactionPipeline

INPUT_DIR = 'input'
MASTER_CSV = 'Validaci√≥n_Categorias_Finsense_04020206_5.csv'


def main():
    print("\n" + "=" * 100)
    print("TEST PIPELINE COMPLETO")
    print("=" * 100)

    # Inicializar pipeline
    print(f"\nüì¶ Inicializando pipeline con master CSV: {MASTER_CSV}")
    pipeline = TransactionPipeline(MASTER_CSV)

    # Test 1: Detecci√≥n de banco
    print("\nüè¶ Test 1: Detecci√≥n de banco")
    print("-" * 100)
    test_files = [
        ('openbank_ES2200730100510135698457.csv', 'openbank'),
        ('MyInvestor_ES5215447889746650686253.csv', 'myinvestor'),
        ('mediolanum_ES2501865001680510084831.csv', 'mediolanum'),
        ('Revolut_ES1215830001199090471794.csv', 'revolut'),
        ('TradeRepublic_ES8015860001420977164411.csv', 'trade_republic'),
        ('MovimientosB100_ES88208001000130433834426.csv', 'b100'),
        ('ABANCA_ES5120800823473040166463.csv', 'abanca'),
    ]

    for filename, expected_bank in test_files:
        detected = pipeline.detect_bank(filename)
        status = "‚úì" if detected == expected_bank else "‚úó"
        print(f"  {status} {filename:60s} ‚Üí {detected}")

    # Test 2: Procesar archivo individual CON clasificaci√≥n
    print("\nüìÑ Test 2: Procesar archivo individual (Openbank) con clasificaci√≥n")
    print("-" * 100)
    filepath = os.path.join(INPUT_DIR, 'openbank_ES2200730100510135698457.csv')
    records = pipeline.process_file(filepath, classify=True)

    print(f"  ‚úì Parseadas: {len(records)} transacciones")

    if records:
        # Verificar campos
        r = records[0]
        campos_requeridos = ['fecha', 'importe', 'descripcion', 'banco', 'cuenta', 'hash',
                            'cat1', 'cat2', 'tipo', 'capa']
        print(f"\n  Campos en transacci√≥n:")
        for campo in campos_requeridos:
            presente = "‚úì" if campo in r else "‚úó"
            valor = r.get(campo, 'MISSING')
            print(f"    {presente} {campo:15s} ‚Üí {valor}")

        # Estad√≠sticas de clasificaci√≥n
        capas = {}
        categorias = {}
        tipos = {}
        for r in records:
            capa = r.get('capa', 0)
            capas[f'Capa {capa}'] = capas.get(f'Capa {capa}', 0) + 1

            cat1 = r.get('cat1', 'MISSING')
            categorias[cat1] = categorias.get(cat1, 0) + 1

            tipo = r.get('tipo', 'MISSING')
            tipos[tipo] = tipos.get(tipo, 0) + 1

        print(f"\n  üìä Distribuci√≥n por capa de clasificaci√≥n:")
        for capa, count in sorted(capas.items()):
            pct = 100 * count / len(records)
            print(f"    {capa}: {count:3d} ({pct:5.1f}%)")

        print(f"\n  üìÇ Categor√≠as (Top 5):")
        top_cats = sorted(categorias.items(), key=lambda x: -x[1])[:5]
        for cat, count in top_cats:
            pct = 100 * count / len(records)
            print(f"    {cat:30s} {count:3d} ({pct:5.1f}%)")

        print(f"\n  üéØ Tipos de transacci√≥n:")
        for tipo, count in sorted(tipos.items(), key=lambda x: -x[1]):
            pct = 100 * count / len(records)
            print(f"    {tipo:20s} {count:3d} ({pct:5.1f}%)")

    # Test 3: Deduplicaci√≥n
    print("\nüîÑ Test 3: Deduplicaci√≥n (procesar mismo archivo dos veces)")
    print("-" * 100)

    # Reset pipeline para test limpio
    pipeline2 = TransactionPipeline(MASTER_CSV)

    records1 = pipeline2.process_file(filepath, classify=False)
    print(f"  Primera pasada:  {len(records1)} transacciones nuevas")

    records2 = pipeline2.process_file(filepath, classify=False)
    print(f"  Segunda pasada:  {len(records2)} transacciones nuevas")

    if len(records2) == 0 and len(records1) > 0:
        print(f"  ‚úì Deduplicaci√≥n funciona correctamente")
    else:
        print(f"  ‚úó ERROR: Deduplicaci√≥n no funciona")

    # Test 4: Procesar directorio completo
    print("\nüìÅ Test 4: Procesar directorio completo CON clasificaci√≥n")
    print("-" * 100)

    # Reset pipeline
    pipeline3 = TransactionPipeline(MASTER_CSV)

    all_records = pipeline3.process_directory(INPUT_DIR, classify=True)

    print(f"\n  üìä Resumen global:")
    print(f"    Total transacciones: {len(all_records)}")

    if all_records:
        # Por banco
        by_bank = {}
        for r in all_records:
            banco = r['banco']
            by_bank[banco] = by_bank.get(banco, 0) + 1

        print(f"\n    Por banco:")
        for banco, count in sorted(by_bank.items(), key=lambda x: -x[1]):
            pct = 100 * count / len(all_records)
            print(f"      {banco:20s} {count:5d} ({pct:5.1f}%)")

        # Cobertura de clasificaci√≥n
        sin_clasificar = sum(1 for r in all_records if r.get('cat1') == 'SIN_CLASIFICAR')
        clasificadas = len(all_records) - sin_clasificar
        pct_clasificadas = 100 * clasificadas / len(all_records) if all_records else 0

        print(f"\n    Cobertura de clasificaci√≥n:")
        print(f"      Clasificadas:     {clasificadas:5d} ({pct_clasificadas:5.1f}%)")
        print(f"      Sin clasificar:   {sin_clasificar:5d} ({100-pct_clasificadas:5.1f}%)")

        if sin_clasificar == 0:
            print(f"\n    ‚úÖ ¬°Todas las transacciones clasificadas!")
        else:
            print(f"\n    ‚ö†Ô∏è  {sin_clasificar} transacciones sin clasificar")

    # Test 5: Estad√≠sticas completas
    print("\nüìà Test 5: Estad√≠sticas completas")
    print("-" * 100)

    pipeline3.print_statistics(all_records)

    print("\n" + "=" * 100)
    print("‚úÖ Tests del pipeline completados")
    print("=" * 100 + "\n")


if __name__ == '__main__':
    main()
